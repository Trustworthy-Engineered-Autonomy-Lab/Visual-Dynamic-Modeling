{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b44677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 23:17:49.707687: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 1s 1ms/step - loss: 1.0967 - mean_absolute_error: 52.0202 - val_loss: 0.0498 - val_mean_absolute_error: 50.3277\n",
      "Epoch 2/15\n",
      "414/414 [==============================] - 0s 882us/step - loss: 0.1919 - mean_absolute_error: 51.6605 - val_loss: 0.0244 - val_mean_absolute_error: 50.2881\n",
      "Epoch 3/15\n",
      "414/414 [==============================] - 0s 870us/step - loss: 0.0604 - mean_absolute_error: 51.5573 - val_loss: 0.0217 - val_mean_absolute_error: 50.2925\n",
      "Epoch 4/15\n",
      "414/414 [==============================] - 0s 855us/step - loss: 0.0341 - mean_absolute_error: 51.5305 - val_loss: 0.0201 - val_mean_absolute_error: 50.2859\n",
      "Epoch 5/15\n",
      "414/414 [==============================] - 0s 857us/step - loss: 0.0283 - mean_absolute_error: 51.5211 - val_loss: 0.0207 - val_mean_absolute_error: 50.2888\n",
      "Epoch 6/15\n",
      "414/414 [==============================] - 0s 852us/step - loss: 0.0266 - mean_absolute_error: 51.5207 - val_loss: 0.0210 - val_mean_absolute_error: 50.2962\n",
      "Epoch 7/15\n",
      "414/414 [==============================] - 0s 856us/step - loss: 0.0260 - mean_absolute_error: 51.5195 - val_loss: 0.0193 - val_mean_absolute_error: 50.2850\n",
      "Epoch 8/15\n",
      "414/414 [==============================] - 0s 853us/step - loss: 0.0255 - mean_absolute_error: 51.5172 - val_loss: 0.0178 - val_mean_absolute_error: 50.2870\n",
      "Epoch 9/15\n",
      "414/414 [==============================] - 0s 856us/step - loss: 0.0248 - mean_absolute_error: 51.5155 - val_loss: 0.0169 - val_mean_absolute_error: 50.2813\n",
      "Epoch 10/15\n",
      "414/414 [==============================] - 0s 855us/step - loss: 0.0243 - mean_absolute_error: 51.5158 - val_loss: 0.0172 - val_mean_absolute_error: 50.2794\n",
      "Epoch 11/15\n",
      "414/414 [==============================] - 0s 850us/step - loss: 0.0241 - mean_absolute_error: 51.5133 - val_loss: 0.0188 - val_mean_absolute_error: 50.2800\n",
      "Epoch 12/15\n",
      "414/414 [==============================] - 0s 849us/step - loss: 0.0242 - mean_absolute_error: 51.5137 - val_loss: 0.0166 - val_mean_absolute_error: 50.2748\n",
      "Epoch 13/15\n",
      "414/414 [==============================] - 0s 859us/step - loss: 0.0240 - mean_absolute_error: 51.5145 - val_loss: 0.0181 - val_mean_absolute_error: 50.2861\n",
      "Epoch 14/15\n",
      "414/414 [==============================] - 0s 904us/step - loss: 0.0232 - mean_absolute_error: 51.5112 - val_loss: 0.0177 - val_mean_absolute_error: 50.2851\n",
      "Epoch 15/15\n",
      "414/414 [==============================] - 0s 856us/step - loss: 0.0235 - mean_absolute_error: 51.5113 - val_loss: 0.0165 - val_mean_absolute_error: 50.2731\n",
      "130/130 [==============================] - 0s 403us/step - loss: 0.0172 - mean_absolute_error: 52.1245\n",
      "Test Loss, Test MAE: [0.017245663329958916, 52.124507904052734]\n",
      "130/130 [==============================] - 0s 361us/step\n",
      "Filtered Mean Squared Error: 236.1602685612411\n",
      "Filtered Root Mean Squared Error: 15.367506907798711\n",
      "Filtered Mean Absolute Error: 10.248521000728502\n",
      "Filtered R-squared Score: 0.9070057888926725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom MSE to handle -999 placeholders\n",
    "def custom_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -999), tf.float32)\n",
    "    error = tf.square(y_pred - y_true) * mask\n",
    "    return tf.reduce_sum(error) / tf.reduce_sum(mask)\n",
    "\n",
    "# Load and prepare data\n",
    "lines = []\n",
    "with open('Final_static_dataset.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "steering_angles, throttles, x_coords_list, flags_list = [], [], [], []\n",
    "\n",
    "for line in lines:\n",
    "    if line.strip():\n",
    "        parts = line.split(': ')\n",
    "        image_number, data = parts[0], parts[1]\n",
    "        control_values, points, flags = eval(data)\n",
    "        steering_angles.append(control_values[0])\n",
    "        throttles.append(control_values[1])\n",
    "        x_coords_list.append([point[0] if point else np.nan for point in points][::-1])  # Reverse the order here\n",
    "\n",
    "df = pd.DataFrame(x_coords_list, columns=['x_farthest', 'x_middle2', 'x_middle1', 'x_closest'])\n",
    "df['steering_angle'], df['throttle'] = steering_angles, throttles\n",
    "\n",
    "for col in ['x_farthest', 'x_middle2', 'x_middle1', 'x_closest']:\n",
    "    df[f'{col}_missing'] = df[col].isna().astype(int)\n",
    "\n",
    "for col in ['x_farthest', 'x_middle2', 'x_middle1', 'x_closest']:\n",
    "    df[f'next_{col}'] = df[col].shift(-1)\n",
    "\n",
    "df = df[:-1]\n",
    "\n",
    "# Replace missing values with -999\n",
    "df.fillna(-999, inplace=True)\n",
    "\n",
    "# Separate features and target variables\n",
    "X = df.drop(columns=[f'next_{col}' for col in ['x_farthest', 'x_middle2', 'x_middle1', 'x_closest']] +\n",
    "                   [f'{col}_missing' for col in ['x_farthest', 'x_middle2', 'x_middle1', 'x_closest']])\n",
    "y_coords = df[[f'next_{col}' for col in ['x_farthest', 'x_middle2', 'x_middle1', 'x_closest']]]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_coords_train, y_coords_test = train_test_split(\n",
    "    X, y_coords, test_size=0.2, random_state=42)\n",
    "\n",
    "# Replace -999 with NaN for scaling\n",
    "X_train.replace(-999, np.nan, inplace=True)\n",
    "X_test.replace(-999, np.nan, inplace=True)\n",
    "y_coords_train.replace(-999, np.nan, inplace=True)\n",
    "y_coords_test.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "feature_scaler = MinMaxScaler()\n",
    "coords_scaler = MinMaxScaler()\n",
    "\n",
    "scaled_features_train = feature_scaler.fit_transform(X_train)\n",
    "scaled_features_test = feature_scaler.transform(X_test)\n",
    "\n",
    "scaled_coords_train = coords_scaler.fit_transform(y_coords_train)\n",
    "scaled_coords_test = coords_scaler.transform(y_coords_test)\n",
    "\n",
    "# Replace NaN back with -999 after scaling\n",
    "X_train_scaled = pd.DataFrame(scaled_features_train, columns=X_train.columns).fillna(-999)\n",
    "X_test_scaled = pd.DataFrame(scaled_features_test, columns=X_test.columns).fillna(-999)\n",
    "\n",
    "y_coords_train_scaled = pd.DataFrame(scaled_coords_train, columns=y_coords_train.columns).fillna(-999)\n",
    "y_coords_test_scaled = pd.DataFrame(scaled_coords_test, columns=y_coords_test.columns).fillna(-999)\n",
    "\n",
    "# Build the model\n",
    "inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "coords_output = Dense(4, name='coords_output')(x)  # Output for coordinates\n",
    "\n",
    "model = Model(inputs=inputs, outputs=coords_output)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=custom_mse,\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_coords_train_scaled, validation_split=0.2, epochs=15, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test_scaled, y_coords_test_scaled)\n",
    "print(f\"Test Loss, Test MAE: {results}\")\n",
    "\n",
    "# Predict coordinates\n",
    "predictions_coords = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate coordinates\n",
    "# Replace -999 with NaN before inverse transform\n",
    "y_coords_test_scaled.replace(-999, np.nan, inplace=True)\n",
    "predictions_coords_df = pd.DataFrame(predictions_coords, columns=y_coords_test.columns)\n",
    "predictions_coords_df.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "# Inverse transform the coordinates\n",
    "y_coords_test_inv = coords_scaler.inverse_transform(y_coords_test_scaled)\n",
    "predictions_coords_inv = coords_scaler.inverse_transform(predictions_coords_df)\n",
    "\n",
    "# Replace NaN back with -999 after inverse transform\n",
    "y_coords_test_inv = pd.DataFrame(y_coords_test_inv, columns=y_coords_test.columns).fillna(-999)\n",
    "predictions_coords_inv = pd.DataFrame(predictions_coords_inv, columns=y_coords_test.columns).fillna(-999)\n",
    "\n",
    "# Apply the mask after inverse transform\n",
    "mask = np.all(y_coords_test_inv != -999, axis=1)\n",
    "filtered_y_test = y_coords_test_inv[mask]\n",
    "filtered_y_pred = predictions_coords_inv[mask]\n",
    "\n",
    "filtered_mse = mean_squared_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_rmse = np.sqrt(filtered_mse)\n",
    "filtered_mae = mean_absolute_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_r2 = r2_score(filtered_y_test, filtered_y_pred)\n",
    "\n",
    "print(f\"Filtered Mean Squared Error: {filtered_mse}\")\n",
    "print(f\"Filtered Root Mean Squared Error: {filtered_rmse}\")\n",
    "print(f\"Filtered Mean Absolute Error: {filtered_mae}\")\n",
    "print(f\"Filtered R-squared Score: {filtered_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846972ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_farthest</th>\n",
       "      <th>x_middle2</th>\n",
       "      <th>x_middle1</th>\n",
       "      <th>x_closest</th>\n",
       "      <th>steering_angle</th>\n",
       "      <th>throttle</th>\n",
       "      <th>x_farthest_missing</th>\n",
       "      <th>x_middle2_missing</th>\n",
       "      <th>x_middle1_missing</th>\n",
       "      <th>x_closest_missing</th>\n",
       "      <th>next_x_farthest</th>\n",
       "      <th>next_x_middle2</th>\n",
       "      <th>next_x_middle1</th>\n",
       "      <th>next_x_closest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20683</th>\n",
       "      <td>81</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.455594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20684</th>\n",
       "      <td>72</td>\n",
       "      <td>70.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>64</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20686</th>\n",
       "      <td>57</td>\n",
       "      <td>56.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20687</th>\n",
       "      <td>49</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20688 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_farthest  x_middle2  x_middle1  x_closest  steering_angle  throttle  \\\n",
       "0             128      128.0      129.0      126.0             0.0  0.500000   \n",
       "1             127      127.0      128.0      129.0             0.0  0.500000   \n",
       "2             127      128.0      129.0      129.0             0.0  0.500000   \n",
       "3             128      128.0      129.0      129.0             0.0  0.500000   \n",
       "4             127      128.0      128.0      129.0             0.0  0.500000   \n",
       "...           ...        ...        ...        ...             ...       ...   \n",
       "20683          81       76.0       74.0       69.0             0.0 -0.455594   \n",
       "20684          72       70.0       68.0       62.0             0.0  0.000000   \n",
       "20685          64       63.0       64.0       62.0             0.0 -0.500000   \n",
       "20686          57       56.0       60.0       55.0             0.0 -0.500000   \n",
       "20687          49       52.0       57.0       54.0             0.0 -0.500000   \n",
       "\n",
       "       x_farthest_missing  x_middle2_missing  x_middle1_missing  \\\n",
       "0                       0                  0                  0   \n",
       "1                       0                  0                  0   \n",
       "2                       0                  0                  0   \n",
       "3                       0                  0                  0   \n",
       "4                       0                  0                  0   \n",
       "...                   ...                ...                ...   \n",
       "20683                   0                  0                  0   \n",
       "20684                   0                  0                  0   \n",
       "20685                   0                  0                  0   \n",
       "20686                   0                  0                  0   \n",
       "20687                   0                  0                  0   \n",
       "\n",
       "       x_closest_missing  next_x_farthest  next_x_middle2  next_x_middle1  \\\n",
       "0                      0            127.0           127.0           128.0   \n",
       "1                      0            127.0           128.0           129.0   \n",
       "2                      0            128.0           128.0           129.0   \n",
       "3                      0            127.0           128.0           128.0   \n",
       "4                      0            127.0           127.0           129.0   \n",
       "...                  ...              ...             ...             ...   \n",
       "20683                  0             72.0            70.0            68.0   \n",
       "20684                  0             64.0            63.0            64.0   \n",
       "20685                  0             57.0            56.0            60.0   \n",
       "20686                  0             49.0            52.0            57.0   \n",
       "20687                  0             43.0            46.0            54.0   \n",
       "\n",
       "       next_x_closest  \n",
       "0               129.0  \n",
       "1               129.0  \n",
       "2               129.0  \n",
       "3               129.0  \n",
       "4               129.0  \n",
       "...               ...  \n",
       "20683            62.0  \n",
       "20684            62.0  \n",
       "20685            55.0  \n",
       "20686            54.0  \n",
       "20687            53.0  \n",
       "\n",
       "[20688 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3afb85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next_x_farthest</th>\n",
       "      <th>next_x_middle2</th>\n",
       "      <th>next_x_middle1</th>\n",
       "      <th>next_x_closest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.785388</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.590698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.786047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>0.133028</td>\n",
       "      <td>0.293023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105505</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.394495</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16545</th>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.401826</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16546</th>\n",
       "      <td>0.646789</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.490826</td>\n",
       "      <td>0.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16547</th>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.680365</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.441860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16548</th>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16549</th>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.433790</td>\n",
       "      <td>0.224771</td>\n",
       "      <td>0.153488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       next_x_farthest  next_x_middle2  next_x_middle1  next_x_closest\n",
       "0             0.798165        0.785388        0.715596        0.590698\n",
       "1             0.527523        0.575342        0.688073        0.786047\n",
       "2             0.137615        0.219178        0.376147     -999.000000\n",
       "3             0.018349        0.059361        0.133028        0.293023\n",
       "4             0.105505        0.219178        0.394495     -999.000000\n",
       "...                ...             ...             ...             ...\n",
       "16545         0.385321        0.401826        0.275229        0.255814\n",
       "16546         0.646789        0.561644        0.490826        0.348837\n",
       "16547         0.821101        0.680365        0.541284        0.441860\n",
       "16548         0.724771        0.684932        0.807339     -999.000000\n",
       "16549         0.495413        0.433790        0.224771        0.153488\n",
       "\n",
       "[16550 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_coords_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33347817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c7516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9344a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d8abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "474d3ce1",
   "metadata": {},
   "source": [
    "### without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0cbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -999), tf.float32) \n",
    "    error = tf.square(y_pred - y_true) * mask  \n",
    "    return tf.reduce_sum(error) / tf.reduce_sum(mask)  \n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('Final_static_dataset.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize lists to hold the data\n",
    "steering_angles = []\n",
    "throttles = []\n",
    "x_coords_list = [] \n",
    "flags_list = []\n",
    "\n",
    "# Process each line in the file\n",
    "for line in lines:\n",
    "    if line.strip():  # Check if the line is not empty\n",
    "        parts = line.split(': ')\n",
    "        image_number, data = parts[0], parts[1]\n",
    "        control_values, points, flags = eval(data)\n",
    "        \n",
    "        # Append only the first two control values to the respective lists\n",
    "        steering_angles.append(control_values[0])\n",
    "        throttles.append(control_values[1])\n",
    "        \n",
    "        # Extract x-coordinates and flags from points\n",
    "        x_coords_list.append([point[0] for point in points])\n",
    "        flags_list.append(flags)\n",
    "\n",
    "df = pd.DataFrame(x_coords_list, columns=['x_closest', 'x_middle1', 'x_middle2', 'x_farthest'])\n",
    "df['steering_angle'], df['throttle'] = steering_angles, throttles\n",
    "\n",
    "for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']:\n",
    "    df[f'next_{col}'] = df[col].shift(-1)\n",
    "df = df[:-1] \n",
    "df.fillna(-999, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f142f360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_closest</th>\n",
       "      <th>x_middle1</th>\n",
       "      <th>x_middle2</th>\n",
       "      <th>x_farthest</th>\n",
       "      <th>steering_angle</th>\n",
       "      <th>throttle</th>\n",
       "      <th>next_x_closest</th>\n",
       "      <th>next_x_middle1</th>\n",
       "      <th>next_x_middle2</th>\n",
       "      <th>next_x_farthest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20683</th>\n",
       "      <td>69</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.455594</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20684</th>\n",
       "      <td>62</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20686</th>\n",
       "      <td>55</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20687</th>\n",
       "      <td>54</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20688 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_closest  x_middle1  x_middle2  x_farthest  steering_angle  throttle  \\\n",
       "0            126      129.0      128.0       128.0             0.0  0.500000   \n",
       "1            129      128.0      127.0       127.0             0.0  0.500000   \n",
       "2            129      129.0      128.0       127.0             0.0  0.500000   \n",
       "3            129      129.0      128.0       128.0             0.0  0.500000   \n",
       "4            129      128.0      128.0       127.0             0.0  0.500000   \n",
       "...          ...        ...        ...         ...             ...       ...   \n",
       "20683         69       74.0       76.0        81.0             0.0 -0.455594   \n",
       "20684         62       68.0       70.0        72.0             0.0  0.000000   \n",
       "20685         62       64.0       63.0        64.0             0.0 -0.500000   \n",
       "20686         55       60.0       56.0        57.0             0.0 -0.500000   \n",
       "20687         54       57.0       52.0        49.0             0.0 -0.500000   \n",
       "\n",
       "       next_x_closest  next_x_middle1  next_x_middle2  next_x_farthest  \n",
       "0               129.0           128.0           127.0            127.0  \n",
       "1               129.0           129.0           128.0            127.0  \n",
       "2               129.0           129.0           128.0            128.0  \n",
       "3               129.0           128.0           128.0            127.0  \n",
       "4               129.0           129.0           127.0            127.0  \n",
       "...               ...             ...             ...              ...  \n",
       "20683            62.0            68.0            70.0             72.0  \n",
       "20684            62.0            64.0            63.0             64.0  \n",
       "20685            55.0            60.0            56.0             57.0  \n",
       "20686            54.0            57.0            52.0             49.0  \n",
       "20687            53.0            54.0            46.0             43.0  \n",
       "\n",
       "[20688 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee44d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 08:47:46.966520: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 1s 829us/step - loss: 719.5031 - mean_absolute_error: 69.6012 - val_loss: 121.5504 - val_mean_absolute_error: 61.6729\n",
      "Epoch 2/15\n",
      "414/414 [==============================] - 0s 602us/step - loss: 106.2843 - mean_absolute_error: 62.3979 - val_loss: 96.0251 - val_mean_absolute_error: 60.5811\n",
      "Epoch 3/15\n",
      "414/414 [==============================] - 0s 578us/step - loss: 91.1785 - mean_absolute_error: 62.1171 - val_loss: 79.3863 - val_mean_absolute_error: 60.0557\n",
      "Epoch 4/15\n",
      "414/414 [==============================] - 0s 568us/step - loss: 85.3900 - mean_absolute_error: 62.3713 - val_loss: 81.4200 - val_mean_absolute_error: 60.4738\n",
      "Epoch 5/15\n",
      "414/414 [==============================] - 0s 563us/step - loss: 84.1049 - mean_absolute_error: 61.8207 - val_loss: 76.4796 - val_mean_absolute_error: 59.7102\n",
      "Epoch 6/15\n",
      "414/414 [==============================] - 0s 565us/step - loss: 82.9782 - mean_absolute_error: 62.6903 - val_loss: 80.7269 - val_mean_absolute_error: 60.4254\n",
      "Epoch 7/15\n",
      "414/414 [==============================] - 0s 584us/step - loss: 81.4422 - mean_absolute_error: 62.2777 - val_loss: 83.6990 - val_mean_absolute_error: 61.4657\n",
      "Epoch 8/15\n",
      "414/414 [==============================] - 0s 666us/step - loss: 81.1456 - mean_absolute_error: 62.5727 - val_loss: 74.3527 - val_mean_absolute_error: 60.5260\n",
      "Epoch 9/15\n",
      "414/414 [==============================] - 0s 577us/step - loss: 77.2411 - mean_absolute_error: 62.4534 - val_loss: 80.8922 - val_mean_absolute_error: 60.0456\n",
      "Epoch 10/15\n",
      "414/414 [==============================] - 0s 590us/step - loss: 80.0498 - mean_absolute_error: 62.4117 - val_loss: 77.1971 - val_mean_absolute_error: 60.6301\n",
      "Epoch 11/15\n",
      "414/414 [==============================] - 0s 618us/step - loss: 80.1845 - mean_absolute_error: 62.3623 - val_loss: 77.9314 - val_mean_absolute_error: 60.8191\n",
      "Epoch 12/15\n",
      "414/414 [==============================] - 0s 605us/step - loss: 78.6118 - mean_absolute_error: 62.4969 - val_loss: 76.6413 - val_mean_absolute_error: 60.5176\n",
      "Epoch 13/15\n",
      "414/414 [==============================] - 0s 608us/step - loss: 76.9405 - mean_absolute_error: 62.3611 - val_loss: 75.7317 - val_mean_absolute_error: 60.5351\n",
      "Epoch 14/15\n",
      "414/414 [==============================] - 0s 608us/step - loss: 76.1737 - mean_absolute_error: 62.2579 - val_loss: 74.0033 - val_mean_absolute_error: 60.6350\n",
      "Epoch 15/15\n",
      "414/414 [==============================] - 0s 622us/step - loss: 77.1415 - mean_absolute_error: 62.4526 - val_loss: 72.4336 - val_mean_absolute_error: 60.7246\n",
      "130/130 [==============================] - 0s 375us/step - loss: 77.8473 - mean_absolute_error: 62.8009\n",
      "130/130 [==============================] - 0s 322us/step\n"
     ]
    }
   ],
   "source": [
    "y_coords = df[[f'next_{col}' for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']]]\n",
    "X = df.drop(columns=[f'next_{col}' for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']])\n",
    "X_train, X_test, y_coords_train, y_coords_test = train_test_split(\n",
    "    X, y_coords ,test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "coords_output = Dense(4, name='coords_output')(x) \n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=coords_output)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss={'coords_output': custom_mse},\n",
    "              metrics={'coords_output': ['mean_absolute_error']})\n",
    "\n",
    "\n",
    "model.fit(X_train, [y_coords_train], validation_split=0.2, epochs=15, batch_size=32)\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, [y_coords_test])\n",
    "\n",
    "predictions_coords = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abd24eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 365us/step\n",
      "Filtered Mean Squared Error: 66.10278436679296\n",
      "Filtered Root Mean Squared Error: 8.13036188412256\n",
      "Filtered Mean Absolute Error: 4.553106772406539\n",
      "Filtered R-squared Score: 0.9738299085043371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "y_pred = model.predict(X_test)\n",
    "coords_pred = y_pred\n",
    "\n",
    "mask = np.all(y_coords_test != -999, axis=1)\n",
    "filtered_y_test = y_coords_test[mask]\n",
    "filtered_y_pred = coords_pred[mask]\n",
    "\n",
    "filtered_mse = mean_squared_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_rmse = np.sqrt(filtered_mse)\n",
    "filtered_mae = mean_absolute_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_r2 = r2_score(filtered_y_test, filtered_y_pred)\n",
    "\n",
    "print(f\"Filtered Mean Squared Error: {filtered_mse}\")\n",
    "print(f\"Filtered Root Mean Squared Error: {filtered_rmse}\")\n",
    "print(f\"Filtered Mean Absolute Error: {filtered_mae}\")\n",
    "print(f\"Filtered R-squared Score: {filtered_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c69ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Custom Predictions: [array([117.677795, 116.920395, 118.86582 , 119.405235], dtype=float32), array([115.33244, 114.04521, 117.28825, 118.62254], dtype=float32), array([113.0606  , 111.28056 , 115.348366, 117.524826], dtype=float32), array([110.91671, 108.58612, 113.1189 , 116.06557], dtype=float32), array([108.92874 , 105.9514  , 110.66641 , 114.246254], dtype=float32), array([107.10786 , 103.381516, 108.052216, 112.0968  ], dtype=float32), array([105.45427 , 100.88878 , 105.33249 , 109.662964], dtype=float32), array([103.96112,  98.48776, 102.55827, 106.99848], dtype=float32), array([102.616844,  96.19257 ,  99.77526 , 104.16017 ], dtype=float32), array([101.406944,  94.01519 ,  97.02356 , 101.20437 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def custom_sequential_predictions(model, X, start_index, n_predictions):\n",
    "    predictions = []\n",
    "    current_features = X.iloc[start_index][['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].values  # Corrected to use directly from DataFrame\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        if start_index + i >= len(X):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        current_controls = X.iloc[start_index + i][['steering_angle', 'throttle']].values\n",
    "        features_with_controls = np.concatenate((current_features, current_controls))  \n",
    "        \n",
    "       \n",
    "        current_features_df = pd.DataFrame([features_with_controls], columns=X.columns)\n",
    "        \n",
    "    \n",
    "        predicted_coords = model.predict(current_features_df)[0]\n",
    "        predictions.append(predicted_coords)\n",
    "        \n",
    "        \n",
    "        current_features = predicted_coords  \n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "custom_df = pd.DataFrame({\n",
    "    'x_closest': [120] * 10,  \n",
    "    'x_middle1': [120] * 10,\n",
    "    'x_middle2': [120] * 10,\n",
    "    'x_farthest': [120] * 10,\n",
    "    'steering_angle':[0] * 10,  \n",
    "    'throttle': np.full(10, 0.5)                \n",
    "})\n",
    "\n",
    "# Call the function with custom data\n",
    "start_index = 0\n",
    "n_predictions = 10\n",
    "custom_predictions = custom_sequential_predictions(model, custom_df, start_index, n_predictions)\n",
    "print(\"Custom Predictions:\", custom_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb60c8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117.677795 116.920395 118.86582  119.405235]\n",
      "[115.33244 114.04521 117.28825 118.62254]\n",
      "[113.0606   111.28056  115.348366 117.524826]\n",
      "[110.91671 108.58612 113.1189  116.06557]\n",
      "[108.92874  105.9514   110.66641  114.246254]\n",
      "[107.10786  103.381516 108.052216 112.0968  ]\n",
      "[105.45427  100.88878  105.33249  109.662964]\n",
      "[103.96112  98.48776 102.55827 106.99848]\n",
      "[102.616844  96.19257   99.77526  104.16017 ]\n",
      "[101.406944  94.01519   97.02356  101.20437 ]\n"
     ]
    }
   ],
   "source": [
    "for i in custom_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f37b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f212460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b51c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "755ee301",
   "metadata": {},
   "source": [
    "## without throttle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4ad0c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa416945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -999), tf.float32) \n",
    "    error = tf.square(y_pred - y_true) * mask  \n",
    "    return tf.reduce_sum(error) / tf.reduce_sum(mask)  \n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('Final_static_dataset.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize lists to hold the data\n",
    "steering_angles = []\n",
    "throttles = []\n",
    "x_coords_list = [] \n",
    "flags_list = []\n",
    "\n",
    "# Process each line in the file\n",
    "for line in lines:\n",
    "    if line.strip():  # Check if the line is not empty\n",
    "        parts = line.split(': ')\n",
    "        image_number, data = parts[0], parts[1]\n",
    "        control_values, points, flags = eval(data)\n",
    "        \n",
    "        # Append only the first two control values to the respective lists\n",
    "        steering_angles.append(control_values[0])\n",
    "        throttles.append(control_values[1])\n",
    "        \n",
    "        # Extract x-coordinates and flags from points\n",
    "        x_coords_list.append([point[0] for point in points])\n",
    "        flags_list.append(flags)\n",
    "\n",
    "df = pd.DataFrame(x_coords_list, columns=['x_closest', 'x_middle1', 'x_middle2', 'x_farthest'])\n",
    "df['steering_angle'], df['throttle'] = steering_angles, throttles\n",
    "\n",
    "for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']:\n",
    "    df[f'next_{col}'] = df[col].shift(-1)\n",
    "df = df[:-1] \n",
    "df.fillna(-999, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8fd451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_closest</th>\n",
       "      <th>x_middle1</th>\n",
       "      <th>x_middle2</th>\n",
       "      <th>x_farthest</th>\n",
       "      <th>steering_angle</th>\n",
       "      <th>throttle</th>\n",
       "      <th>next_x_closest</th>\n",
       "      <th>next_x_middle1</th>\n",
       "      <th>next_x_middle2</th>\n",
       "      <th>next_x_farthest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20683</th>\n",
       "      <td>69</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.455594</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20684</th>\n",
       "      <td>62</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20686</th>\n",
       "      <td>55</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20687</th>\n",
       "      <td>54</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20688 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_closest  x_middle1  x_middle2  x_farthest  steering_angle  throttle  \\\n",
       "0            126      129.0      128.0       128.0             0.0  0.500000   \n",
       "1            129      128.0      127.0       127.0             0.0  0.500000   \n",
       "2            129      129.0      128.0       127.0             0.0  0.500000   \n",
       "3            129      129.0      128.0       128.0             0.0  0.500000   \n",
       "4            129      128.0      128.0       127.0             0.0  0.500000   \n",
       "...          ...        ...        ...         ...             ...       ...   \n",
       "20683         69       74.0       76.0        81.0             0.0 -0.455594   \n",
       "20684         62       68.0       70.0        72.0             0.0  0.000000   \n",
       "20685         62       64.0       63.0        64.0             0.0 -0.500000   \n",
       "20686         55       60.0       56.0        57.0             0.0 -0.500000   \n",
       "20687         54       57.0       52.0        49.0             0.0 -0.500000   \n",
       "\n",
       "       next_x_closest  next_x_middle1  next_x_middle2  next_x_farthest  \n",
       "0               129.0           128.0           127.0            127.0  \n",
       "1               129.0           129.0           128.0            127.0  \n",
       "2               129.0           129.0           128.0            128.0  \n",
       "3               129.0           128.0           128.0            127.0  \n",
       "4               129.0           129.0           127.0            127.0  \n",
       "...               ...             ...             ...              ...  \n",
       "20683            62.0            68.0            70.0             72.0  \n",
       "20684            62.0            64.0            63.0             64.0  \n",
       "20685            55.0            60.0            56.0             57.0  \n",
       "20686            54.0            57.0            52.0             49.0  \n",
       "20687            53.0            54.0            46.0             43.0  \n",
       "\n",
       "[20688 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c401a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "414/414 [==============================] - 0s 761us/step - loss: 985.7506 - mean_absolute_error: 70.0916 - val_loss: 106.2807 - val_mean_absolute_error: 60.7676\n",
      "Epoch 2/15\n",
      "414/414 [==============================] - 0s 565us/step - loss: 99.8474 - mean_absolute_error: 62.0323 - val_loss: 85.2376 - val_mean_absolute_error: 60.3760\n",
      "Epoch 3/15\n",
      "414/414 [==============================] - 0s 756us/step - loss: 88.4381 - mean_absolute_error: 62.2012 - val_loss: 88.3836 - val_mean_absolute_error: 59.8390\n",
      "Epoch 4/15\n",
      "414/414 [==============================] - 0s 655us/step - loss: 83.8533 - mean_absolute_error: 62.1018 - val_loss: 80.9152 - val_mean_absolute_error: 60.8026\n",
      "Epoch 5/15\n",
      "414/414 [==============================] - 0s 574us/step - loss: 84.2025 - mean_absolute_error: 62.3609 - val_loss: 97.5067 - val_mean_absolute_error: 61.5916\n",
      "Epoch 6/15\n",
      "414/414 [==============================] - 0s 578us/step - loss: 84.8744 - mean_absolute_error: 62.6122 - val_loss: 83.3785 - val_mean_absolute_error: 60.5613\n",
      "Epoch 7/15\n",
      "414/414 [==============================] - 0s 598us/step - loss: 82.2986 - mean_absolute_error: 62.5789 - val_loss: 76.6485 - val_mean_absolute_error: 60.8280\n",
      "Epoch 8/15\n",
      "414/414 [==============================] - 0s 558us/step - loss: 81.5785 - mean_absolute_error: 62.4660 - val_loss: 79.4884 - val_mean_absolute_error: 60.8203\n",
      "Epoch 9/15\n",
      "414/414 [==============================] - 0s 573us/step - loss: 80.1467 - mean_absolute_error: 62.4041 - val_loss: 78.0148 - val_mean_absolute_error: 61.0400\n",
      "Epoch 10/15\n",
      "414/414 [==============================] - 0s 575us/step - loss: 81.7621 - mean_absolute_error: 62.3784 - val_loss: 82.2233 - val_mean_absolute_error: 61.3230\n",
      "Epoch 11/15\n",
      "414/414 [==============================] - 0s 554us/step - loss: 83.1148 - mean_absolute_error: 62.4245 - val_loss: 76.4967 - val_mean_absolute_error: 60.8865\n",
      "Epoch 12/15\n",
      "414/414 [==============================] - 0s 617us/step - loss: 79.4670 - mean_absolute_error: 62.3402 - val_loss: 73.6567 - val_mean_absolute_error: 60.2278\n",
      "Epoch 13/15\n",
      "414/414 [==============================] - 0s 566us/step - loss: 79.8183 - mean_absolute_error: 62.3661 - val_loss: 75.7769 - val_mean_absolute_error: 60.2949\n",
      "Epoch 14/15\n",
      "414/414 [==============================] - 0s 560us/step - loss: 77.4362 - mean_absolute_error: 62.3942 - val_loss: 75.1396 - val_mean_absolute_error: 60.9074\n",
      "Epoch 15/15\n",
      "414/414 [==============================] - 0s 590us/step - loss: 77.6987 - mean_absolute_error: 62.4818 - val_loss: 73.8750 - val_mean_absolute_error: 60.7983\n",
      "130/130 [==============================] - 0s 420us/step - loss: 78.6481 - mean_absolute_error: 62.8378\n",
      "130/130 [==============================] - 0s 308us/step\n"
     ]
    }
   ],
   "source": [
    "y_coords = df[[f'next_{col}' for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']]]\n",
    "\n",
    "# Exclude 'throttle' from the feature set\n",
    "X = df.drop(columns=[f'next_{col}' for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']] + ['throttle'])\n",
    "\n",
    "X_train, X_test, y_coords_train, y_coords_test = train_test_split(\n",
    "    X, y_coords ,test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "coords_output = Dense(4, name='coords_output')(x) \n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=coords_output)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss={'coords_output': custom_mse},\n",
    "              metrics={'coords_output': ['mean_absolute_error']})\n",
    "\n",
    "\n",
    "model.fit(X_train, [y_coords_train], validation_split=0.2, epochs=15, batch_size=32)\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, [y_coords_test])\n",
    "\n",
    "predictions_coords = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1608a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 316us/step\n",
      "Filtered Mean Squared Error: 66.86386831747993\n",
      "Filtered Root Mean Squared Error: 8.177032977644147\n",
      "Filtered Mean Absolute Error: 4.507114190064607\n",
      "Filtered R-squared Score: 0.9736754522193171\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "y_pred = model.predict(X_test)\n",
    "coords_pred = y_pred\n",
    "\n",
    "mask = np.all(y_coords_test != -999, axis=1)\n",
    "filtered_y_test = y_coords_test[mask]\n",
    "filtered_y_pred = coords_pred[mask]\n",
    "\n",
    "filtered_mse = mean_squared_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_rmse = np.sqrt(filtered_mse)\n",
    "filtered_mae = mean_absolute_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_r2 = r2_score(filtered_y_test, filtered_y_pred)\n",
    "\n",
    "print(f\"Filtered Mean Squared Error: {filtered_mse}\")\n",
    "print(f\"Filtered Root Mean Squared Error: {filtered_rmse}\")\n",
    "print(f\"Filtered Mean Absolute Error: {filtered_mae}\")\n",
    "print(f\"Filtered R-squared Score: {filtered_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14fc987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Custom Predictions: [array([119.2578  , 120.049835, 119.24323 , 118.78214 ], dtype=float32), array([118.503586, 120.02544 , 118.66386 , 117.74681 ], dtype=float32), array([117.71533, 119.93729, 118.23126, 116.90391], dtype=float32), array([116.878265, 119.78879 , 117.91637 , 116.24704 ], dtype=float32), array([115.98268 , 119.579185, 117.69197 , 115.75995 ], dtype=float32), array([115.02262, 119.30557, 117.53279, 115.42093], dtype=float32), array([113.994835, 118.96399 , 117.41567 , 115.20542 ], dtype=float32), array([112.89822 , 118.550316, 117.3195  , 115.08803 ], dtype=float32), array([111.7333  , 118.06084 , 117.22521 , 115.043564], dtype=float32), array([110.50186, 117.49237, 117.11581, 115.04782], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def custom_sequential_predictions(model, X, start_index, n_predictions):\n",
    "    predictions = []\n",
    "    current_features = X.iloc[start_index][['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].values  # Corrected to use directly from DataFrame\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        if start_index + i >= len(X):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        current_controls = X.iloc[start_index + i][['steering_angle']].values\n",
    "        features_with_controls = np.concatenate((current_features, current_controls))  \n",
    "       \n",
    "        current_features_df = pd.DataFrame([features_with_controls], columns=X.columns)\n",
    "        \n",
    "    \n",
    "        predicted_coords = model.predict(current_features_df)[0]\n",
    "        predictions.append(predicted_coords)\n",
    "        \n",
    "        \n",
    "        current_features = predicted_coords  \n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "custom_df = pd.DataFrame({\n",
    "    'x_closest': [120] * 10,  \n",
    "    'x_middle1': [120] * 10,\n",
    "    'x_middle2': [120] * 10,\n",
    "    'x_farthest': [120] * 10,\n",
    "    'steering_angle':[0] * 10,                \n",
    "})\n",
    "\n",
    "# Call the function with custom data\n",
    "start_index = 0\n",
    "n_predictions = 10\n",
    "custom_predictions = custom_sequential_predictions(model, custom_df, start_index, n_predictions)\n",
    "print(\"Custom Predictions:\", custom_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b3b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119.2578   120.049835 119.24323  118.78214 ]\n",
      "[118.503586 120.02544  118.66386  117.74681 ]\n",
      "[117.71533 119.93729 118.23126 116.90391]\n",
      "[116.878265 119.78879  117.91637  116.24704 ]\n",
      "[115.98268  119.579185 117.69197  115.75995 ]\n",
      "[115.02262 119.30557 117.53279 115.42093]\n",
      "[113.994835 118.96399  117.41567  115.20542 ]\n",
      "[112.89822  118.550316 117.3195   115.08803 ]\n",
      "[111.7333   118.06084  117.22521  115.043564]\n",
      "[110.50186 117.49237 117.11581 115.04782]\n"
     ]
    }
   ],
   "source": [
    "for i in custom_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7b15eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "model.save('NN_NoScale.h5')  # saves to HDF5 file\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6b33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "102cba5a",
   "metadata": {},
   "source": [
    "## NN with normalization and without throttle( Min max Scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "331a6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "414/414 [==============================] - 1s 775us/step - loss: 4511.8594 - mean_absolute_error: 100.7553 - val_loss: 566.7874 - val_mean_absolute_error: 73.4547\n",
      "Epoch 2/20\n",
      "414/414 [==============================] - 0s 710us/step - loss: 482.1287 - mean_absolute_error: 73.2666 - val_loss: 461.4359 - val_mean_absolute_error: 71.2615\n",
      "Epoch 3/20\n",
      "414/414 [==============================] - 0s 596us/step - loss: 408.7134 - mean_absolute_error: 71.7348 - val_loss: 351.9513 - val_mean_absolute_error: 69.0695\n",
      "Epoch 4/20\n",
      "414/414 [==============================] - 0s 634us/step - loss: 261.7370 - mean_absolute_error: 68.2698 - val_loss: 188.1418 - val_mean_absolute_error: 64.8292\n",
      "Epoch 5/20\n",
      "414/414 [==============================] - 0s 626us/step - loss: 154.8386 - mean_absolute_error: 64.6701 - val_loss: 135.5050 - val_mean_absolute_error: 62.4306\n",
      "Epoch 6/20\n",
      "414/414 [==============================] - 0s 606us/step - loss: 130.0042 - mean_absolute_error: 63.4324 - val_loss: 123.3358 - val_mean_absolute_error: 61.8650\n",
      "Epoch 7/20\n",
      "414/414 [==============================] - 0s 617us/step - loss: 120.0907 - mean_absolute_error: 63.0812 - val_loss: 114.4273 - val_mean_absolute_error: 61.6118\n",
      "Epoch 8/20\n",
      "414/414 [==============================] - 0s 673us/step - loss: 113.3117 - mean_absolute_error: 62.8617 - val_loss: 108.6418 - val_mean_absolute_error: 61.3756\n",
      "Epoch 9/20\n",
      "414/414 [==============================] - 0s 606us/step - loss: 108.2169 - mean_absolute_error: 62.6887 - val_loss: 103.7457 - val_mean_absolute_error: 61.1281\n",
      "Epoch 10/20\n",
      "414/414 [==============================] - 0s 626us/step - loss: 104.9208 - mean_absolute_error: 62.5505 - val_loss: 100.9961 - val_mean_absolute_error: 60.9866\n",
      "Epoch 11/20\n",
      "414/414 [==============================] - 0s 662us/step - loss: 102.1753 - mean_absolute_error: 62.4253 - val_loss: 98.5660 - val_mean_absolute_error: 60.8878\n",
      "Epoch 12/20\n",
      "414/414 [==============================] - 0s 609us/step - loss: 100.4692 - mean_absolute_error: 62.3341 - val_loss: 97.0346 - val_mean_absolute_error: 60.7749\n",
      "Epoch 13/20\n",
      "414/414 [==============================] - 0s 602us/step - loss: 99.3114 - mean_absolute_error: 62.2693 - val_loss: 96.8064 - val_mean_absolute_error: 60.6855\n",
      "Epoch 14/20\n",
      "414/414 [==============================] - 0s 641us/step - loss: 98.4979 - mean_absolute_error: 62.2179 - val_loss: 95.7145 - val_mean_absolute_error: 60.7250\n",
      "Epoch 15/20\n",
      "414/414 [==============================] - 0s 622us/step - loss: 98.0532 - mean_absolute_error: 62.2021 - val_loss: 95.1451 - val_mean_absolute_error: 60.6791\n",
      "Epoch 16/20\n",
      "414/414 [==============================] - 0s 685us/step - loss: 97.4905 - mean_absolute_error: 62.1624 - val_loss: 95.1292 - val_mean_absolute_error: 60.6799\n",
      "Epoch 17/20\n",
      "414/414 [==============================] - 0s 811us/step - loss: 96.8611 - mean_absolute_error: 62.1358 - val_loss: 94.7738 - val_mean_absolute_error: 60.6752\n",
      "Epoch 18/20\n",
      "414/414 [==============================] - 1s 3ms/step - loss: 96.9091 - mean_absolute_error: 62.1148 - val_loss: 94.4205 - val_mean_absolute_error: 60.6285\n",
      "Epoch 19/20\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 96.2282 - mean_absolute_error: 62.1202 - val_loss: 93.2680 - val_mean_absolute_error: 60.5538\n",
      "Epoch 20/20\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 95.9798 - mean_absolute_error: 62.0867 - val_loss: 93.9639 - val_mean_absolute_error: 60.6044\n",
      "130/130 [==============================] - 0s 992us/step - loss: 101.0000 - mean_absolute_error: 62.5271\n",
      "130/130 [==============================] - 0s 857us/step\n",
      "130/130 [==============================] - 0s 741us/step\n",
      "Filtered Mean Squared Error: 81.45763325784783\n",
      "Filtered Root Mean Squared Error: 9.025388260781241\n",
      "Filtered Mean Absolute Error: 5.504834471071319\n",
      "Filtered R-squared Score: 0.967996830443007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -999), tf.float32)\n",
    "    error = tf.square(y_pred - y_true) * mask\n",
    "    return tf.reduce_sum(error) / tf.reduce_sum(mask)\n",
    "\n",
    "# Load and preprocess data\n",
    "lines = []\n",
    "with open('Final_static_dataset.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "steering_angles, throttles, x_coords_list, flags_list = [], [], [], []\n",
    "for line in lines:\n",
    "    if line.strip():\n",
    "        parts = line.split(': ')\n",
    "        image_number, data = parts[0], parts[1]\n",
    "        control_values, points, flags = eval(data)\n",
    "        steering_angles.append(control_values[0])\n",
    "        throttles.append(control_values[1])\n",
    "        x_coords_list.append([point[0] for point in points])\n",
    "\n",
    "df = pd.DataFrame(x_coords_list, columns=['x_closest', 'x_middle1', 'x_middle2', 'x_farthest'])\n",
    "df['steering_angle'] = steering_angles\n",
    "\n",
    "for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']:\n",
    "    df[f'next_{col}'] = df[col].shift(-1)\n",
    "df = df[:-1]\n",
    "\n",
    "# Replace -999 with NaN for scaling purposes\n",
    "df.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "y_coords = df[[f'next_{col}' for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].copy()]\n",
    "X = df[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest', 'steering_angle']].copy()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_coords_train, y_coords_test = train_test_split(X, y_coords, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize two scalers\n",
    "#scaler =  MinMaxScaler()\n",
    "\n",
    "scaler_coords = MinMaxScaler()\n",
    "scaler_steering = MinMaxScaler()\n",
    "\n",
    "# Fit the scalers on the appropriate data\n",
    "scaler_coords.fit(X_train[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].fillna(X_train.mean()))\n",
    "scaler_steering.fit(X_train[['steering_angle']])\n",
    "\n",
    "# Transform the data\n",
    "X_train_coords_scaled = scaler_coords.transform(X_train[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].fillna(X_train.mean()))\n",
    "X_train_steering_scaled = scaler_steering.transform(X_train[['steering_angle']])\n",
    "\n",
    "X_test_coords_scaled = scaler_coords.transform(X_test[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].fillna(X_train.mean()))\n",
    "X_test_steering_scaled = scaler_steering.transform(X_test[['steering_angle']])\n",
    "\n",
    "# Concatenate the scaled features back into a single array for model input\n",
    "X_train_scaled = np.hstack((X_train_coords_scaled, X_train_steering_scaled))\n",
    "X_test_scaled = np.hstack((X_test_coords_scaled, X_test_steering_scaled))\n",
    "\n",
    "# Restore -999 in targets after scaling\n",
    "y_coords_train.fillna(-999, inplace=True)\n",
    "y_coords_test.fillna(-999, inplace=True)\n",
    "\n",
    "\n",
    "# Build model\n",
    "inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "coords_output = Dense(4, name='coords_output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=coords_output)\n",
    "model.compile(optimizer=Adam(), loss={'coords_output': custom_mse}, metrics={'coords_output': ['mean_absolute_error']})\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_scaled, y_coords_train, validation_split=0.2, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate model\n",
    "results = model.evaluate(X_test_scaled, y_coords_test)\n",
    "predictions_coords = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mask = np.all(y_coords_test != -999, axis=1)\n",
    "filtered_y_test = y_coords_test[mask]\n",
    "filtered_y_pred = y_pred[mask]\n",
    "\n",
    "filtered_mse = mean_squared_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_rmse = np.sqrt(filtered_mse)\n",
    "filtered_mae = mean_absolute_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_r2 = r2_score(filtered_y_test, filtered_y_pred)\n",
    "\n",
    "print(f\"Filtered Mean Squared Error: {filtered_mse}\")\n",
    "print(f\"Filtered Root Mean Squared Error: {filtered_rmse}\")\n",
    "print(f\"Filtered Mean Absolute Error: {filtered_mae}\")\n",
    "print(f\"Filtered R-squared Score: {filtered_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "641c3049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Step 1: Predicted Coordinates: [122.283585 124.09933  123.67944  121.23071 ]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Step 2: Predicted Coordinates: [124.677734 127.570724 127.77012  124.96136 ]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Step 3: Predicted Coordinates: [127.01237 130.85974 131.9965  129.48508]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Step 4: Predicted Coordinates: [129.24684 134.05699 136.28326 134.29625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Step 5: Predicted Coordinates: [131.36604 137.17892 140.5947  139.23627]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Step 6: Predicted Coordinates: [133.36241 140.2218  144.90662 144.24321]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Step 7: Predicted Coordinates: [135.23096 143.17719 149.19856 149.28232]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Step 8: Predicted Coordinates: [136.968   146.03569 153.4518  154.32712]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Step 9: Predicted Coordinates: [138.57066 148.78838 157.64859 159.3541 ]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Step 10: Predicted Coordinates: [140.03693 151.42693 161.77225 164.34114]\n"
     ]
    }
   ],
   "source": [
    "def custom_sequential_predictions(model, scaler_coords, scaler_steering, X, start_index, n_predictions):\n",
    "    predictions = []\n",
    "    # Retrieve initial features and control inputs\n",
    "    current_features = X.iloc[start_index:start_index + 1][['x_closest', 'x_middle1', 'x_middle2', 'x_farthest', 'steering_angle']]\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        # Separate coordinates and steering for scaling\n",
    "        input_coords = current_features[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']]\n",
    "        input_steering = current_features[['steering_angle']]\n",
    "\n",
    "        # Scale the features for model input\n",
    "        scaled_coords = scaler_coords.transform(input_coords)\n",
    "        scaled_steering = scaler_steering.transform(input_steering)\n",
    "\n",
    "        # Combine scaled features for model input\n",
    "        model_input = np.hstack((scaled_coords, scaled_steering))\n",
    "\n",
    "        # Predict the next coordinates using the scaled features\n",
    "        predicted_coords = model.predict(model_input)[0]\n",
    "        predictions.append(predicted_coords)\n",
    "\n",
    "        # Update current_features for the next prediction\n",
    "        # Creating a new DataFrame for next prediction input\n",
    "        next_features = pd.DataFrame([predicted_coords], columns=['x_closest', 'x_middle1', 'x_middle2', 'x_farthest'])\n",
    "        next_features['steering_angle'] = X.iloc[start_index + i + 1]['steering_angle'] if start_index + i + 1 < len(X) else X.iloc[-1]['steering_angle']\n",
    "\n",
    "        # Replace current features with next_features\n",
    "        current_features = next_features\n",
    "\n",
    "        print(f\"Step {i + 1}: Predicted Coordinates: {predicted_coords}\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "custom_df = pd.DataFrame({\n",
    "    'x_closest': [120] * 10,  \n",
    "    'x_middle1': [120] * 10,\n",
    "    'x_middle2': [120] * 10,\n",
    "    'x_farthest': [120] * 10,\n",
    "    'steering_angle': [1] * 10 \n",
    "})\n",
    "\n",
    "start_index = 0\n",
    "n_predictions = 10\n",
    "custom_predictions = custom_sequential_predictions(model, scaler_coords, scaler_steering, custom_df, start_index, n_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1174839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaler Parameters:\n",
      "Minima: [-0.01376147 -0.01376147 -0.01376147 -0.01382488]\n",
      "Scale factors: [0.00458716 0.00458716 0.00458716 0.00460829]\n",
      "\n",
      "Steering Scaler Parameters:\n",
      "Minima: [0.5]\n",
      "Scale factors: [0.5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Scaler Parameters:\")\n",
    "print(\"Minima:\", scaler_coords.min_)\n",
    "print(\"Scale factors:\", scaler_coords.scale_)\n",
    "\n",
    "print(\"\\nSteering Scaler Parameters:\")\n",
    "print(\"Minima:\", scaler_steering.min_)\n",
    "print(\"Scale factors:\", scaler_steering.scale_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8309cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (16550, 5)\n",
      "Shape of input features right before prediction: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data:\", X_train_scaled.shape)\n",
    "print(\"Shape of input features right before prediction:\", scaled_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f7b1898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features to the model: [[0.54587156 0.54587156 0.54587156 0.5483871 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input features to the model:\", scaled_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d995c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Output for test input: [[111.043785 112.21169  111.34141  112.31102 ]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([[0.5, 0.5, 0.5, 0.5, 0.5]])  # Example simple input\n",
    "try:\n",
    "    test_output = model.predict(test_input)\n",
    "    print(\"Output for test input:\", test_output)\n",
    "except Exception as e:\n",
    "    print(\"Error during model prediction with test input:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62039028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a1d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model.save('NN_MinMaxScale.h5')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "197fad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the scalers to disk\n",
    "with open('scaler_coords_minmax.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_coords, file)\n",
    "\n",
    "with open('scaler_steering_minmax.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_steering, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5159336",
   "metadata": {},
   "source": [
    "## NN with normalization and without throttle( Standard Scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc8189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 17:36:57.494417: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 1s 790us/step - loss: 4729.6240 - mean_absolute_error: 104.6386 - val_loss: 586.5490 - val_mean_absolute_error: 74.9460\n",
      "Epoch 2/20\n",
      "414/414 [==============================] - 0s 604us/step - loss: 307.4893 - mean_absolute_error: 69.9591 - val_loss: 182.5223 - val_mean_absolute_error: 64.8321\n",
      "Epoch 3/20\n",
      "414/414 [==============================] - 0s 575us/step - loss: 142.6162 - mean_absolute_error: 64.6290 - val_loss: 115.4601 - val_mean_absolute_error: 61.9966\n",
      "Epoch 4/20\n",
      "414/414 [==============================] - 0s 558us/step - loss: 107.3141 - mean_absolute_error: 62.9906 - val_loss: 98.0410 - val_mean_absolute_error: 61.1209\n",
      "Epoch 5/20\n",
      "414/414 [==============================] - 0s 560us/step - loss: 98.2452 - mean_absolute_error: 62.4460 - val_loss: 93.1610 - val_mean_absolute_error: 60.8490\n",
      "Epoch 6/20\n",
      "414/414 [==============================] - 0s 567us/step - loss: 94.3272 - mean_absolute_error: 62.2286 - val_loss: 89.8889 - val_mean_absolute_error: 60.6349\n",
      "Epoch 7/20\n",
      "414/414 [==============================] - 0s 557us/step - loss: 92.1394 - mean_absolute_error: 62.1140 - val_loss: 87.8715 - val_mean_absolute_error: 60.5455\n",
      "Epoch 8/20\n",
      "414/414 [==============================] - 0s 557us/step - loss: 90.9445 - mean_absolute_error: 62.0426 - val_loss: 87.3484 - val_mean_absolute_error: 60.4935\n",
      "Epoch 9/20\n",
      "414/414 [==============================] - 0s 563us/step - loss: 89.5020 - mean_absolute_error: 61.9493 - val_loss: 87.4810 - val_mean_absolute_error: 60.5026\n",
      "Epoch 10/20\n",
      "414/414 [==============================] - 0s 559us/step - loss: 88.1794 - mean_absolute_error: 61.8680 - val_loss: 84.6470 - val_mean_absolute_error: 60.2903\n",
      "Epoch 11/20\n",
      "414/414 [==============================] - 0s 562us/step - loss: 87.1400 - mean_absolute_error: 61.7733 - val_loss: 83.3685 - val_mean_absolute_error: 60.2924\n",
      "Epoch 12/20\n",
      "414/414 [==============================] - 0s 563us/step - loss: 85.8581 - mean_absolute_error: 61.6798 - val_loss: 82.9808 - val_mean_absolute_error: 60.2633\n",
      "Epoch 13/20\n",
      "414/414 [==============================] - 0s 559us/step - loss: 85.9291 - mean_absolute_error: 61.6527 - val_loss: 83.9322 - val_mean_absolute_error: 60.2431\n",
      "Epoch 14/20\n",
      "414/414 [==============================] - 0s 557us/step - loss: 84.7164 - mean_absolute_error: 61.5503 - val_loss: 81.6585 - val_mean_absolute_error: 60.1092\n",
      "Epoch 15/20\n",
      "414/414 [==============================] - 0s 566us/step - loss: 84.3682 - mean_absolute_error: 61.5241 - val_loss: 83.5377 - val_mean_absolute_error: 60.1439\n",
      "Epoch 16/20\n",
      "414/414 [==============================] - 0s 559us/step - loss: 84.3443 - mean_absolute_error: 61.5404 - val_loss: 80.8429 - val_mean_absolute_error: 59.8868\n",
      "Epoch 17/20\n",
      "414/414 [==============================] - 0s 627us/step - loss: 83.5312 - mean_absolute_error: 61.4633 - val_loss: 81.0479 - val_mean_absolute_error: 59.8545\n",
      "Epoch 18/20\n",
      "414/414 [==============================] - 0s 562us/step - loss: 83.6033 - mean_absolute_error: 61.4564 - val_loss: 80.5019 - val_mean_absolute_error: 59.9368\n",
      "Epoch 19/20\n",
      "414/414 [==============================] - 0s 557us/step - loss: 83.3843 - mean_absolute_error: 61.4490 - val_loss: 81.2533 - val_mean_absolute_error: 59.8621\n",
      "Epoch 20/20\n",
      "414/414 [==============================] - 0s 559us/step - loss: 83.5552 - mean_absolute_error: 61.4443 - val_loss: 80.6642 - val_mean_absolute_error: 59.8960\n",
      "130/130 [==============================] - 0s 372us/step - loss: 86.8497 - mean_absolute_error: 61.8706\n",
      "130/130 [==============================] - 0s 309us/step\n",
      "130/130 [==============================] - 0s 304us/step\n",
      "Filtered Mean Squared Error: 70.26325437099611\n",
      "Filtered Root Mean Squared Error: 8.3823179593115\n",
      "Filtered Mean Absolute Error: 4.763634725402473\n",
      "Filtered R-squared Score: 0.9724092261033297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -999), tf.float32)\n",
    "    error = tf.square(y_pred - y_true) * mask\n",
    "    return tf.reduce_sum(error) / tf.reduce_sum(mask)\n",
    "\n",
    "# Load and preprocess data\n",
    "lines = []\n",
    "with open('Final_static_dataset.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "steering_angles, throttles, x_coords_list, flags_list = [], [], [], []\n",
    "for line in lines:\n",
    "    if line.strip():\n",
    "        parts = line.split(': ')\n",
    "        image_number, data = parts[0], parts[1]\n",
    "        control_values, points, flags = eval(data)\n",
    "        steering_angles.append(control_values[0])\n",
    "        throttles.append(control_values[1])\n",
    "        x_coords_list.append([point[0] for point in points])\n",
    "\n",
    "df = pd.DataFrame(x_coords_list, columns=['x_closest', 'x_middle1', 'x_middle2', 'x_farthest'])\n",
    "df['steering_angle'] = steering_angles\n",
    "\n",
    "for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']:\n",
    "    df[f'next_{col}'] = df[col].shift(-1)\n",
    "df = df[:-1]\n",
    "\n",
    "# Replace -999 with NaN for scaling purposes\n",
    "df.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "y_coords = df[[f'next_{col}' for col in ['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].copy()]\n",
    "X = df[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest', 'steering_angle']].copy()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_coords_train, y_coords_test = train_test_split(X, y_coords, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize two scalers\n",
    "#scaler =  StandardScaler()\n",
    "\n",
    "scaler_coords = StandardScaler()\n",
    "scaler_steering = StandardScaler()\n",
    "\n",
    "# Fit the scalers on the appropriate data\n",
    "scaler_coords.fit(X_train[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].fillna(X_train.mean()))\n",
    "scaler_steering.fit(X_train[['steering_angle']])\n",
    "\n",
    "# Transform the data\n",
    "X_train_coords_scaled = scaler_coords.transform(X_train[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].fillna(X_train.mean()))\n",
    "X_train_steering_scaled = scaler_steering.transform(X_train[['steering_angle']])\n",
    "\n",
    "X_test_coords_scaled = scaler_coords.transform(X_test[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']].fillna(X_train.mean()))\n",
    "X_test_steering_scaled = scaler_steering.transform(X_test[['steering_angle']])\n",
    "\n",
    "# Concatenate the scaled features back into a single array for model input\n",
    "X_train_scaled = np.hstack((X_train_coords_scaled, X_train_steering_scaled))\n",
    "X_test_scaled = np.hstack((X_test_coords_scaled, X_test_steering_scaled))\n",
    "\n",
    "# Restore -999 in targets after scaling\n",
    "y_coords_train.fillna(-999, inplace=True)\n",
    "y_coords_test.fillna(-999, inplace=True)\n",
    "\n",
    "\n",
    "# Build model\n",
    "inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "coords_output = Dense(4, name='coords_output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=coords_output)\n",
    "model.compile(optimizer=Adam(), loss={'coords_output': custom_mse}, metrics={'coords_output': ['mean_absolute_error']})\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_scaled, y_coords_train, validation_split=0.2, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate model\n",
    "results = model.evaluate(X_test_scaled, y_coords_test)\n",
    "predictions_coords = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mask = np.all(y_coords_test != -999, axis=1)\n",
    "filtered_y_test = y_coords_test[mask]\n",
    "filtered_y_pred = y_pred[mask]\n",
    "\n",
    "filtered_mse = mean_squared_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_rmse = np.sqrt(filtered_mse)\n",
    "filtered_mae = mean_absolute_error(filtered_y_test, filtered_y_pred)\n",
    "filtered_r2 = r2_score(filtered_y_test, filtered_y_pred)\n",
    "\n",
    "print(f\"Filtered Mean Squared Error: {filtered_mse}\")\n",
    "print(f\"Filtered Root Mean Squared Error: {filtered_rmse}\")\n",
    "print(f\"Filtered Mean Absolute Error: {filtered_mae}\")\n",
    "print(f\"Filtered R-squared Score: {filtered_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa9439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Step 1: Predicted Coordinates: [118.809074 119.65357  117.84341  118.66243 ]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Step 2: Predicted Coordinates: [117.691574 119.031166 116.127716 116.22561 ]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Step 3: Predicted Coordinates: [116.62981  118.28177  114.651115 113.94006 ]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Step 4: Predicted Coordinates: [115.611244 117.45203  113.30537  111.949066]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Step 5: Predicted Coordinates: [114.62954 116.56326 112.02467 110.18133]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Step 6: Predicted Coordinates: [113.68325 115.63026 110.76768 108.54841]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Step 7: Predicted Coordinates: [112.77443  114.665886 109.5092   106.982   ]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Step 8: Predicted Coordinates: [111.90767 113.68244 108.23533 105.43562]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Step 9: Predicted Coordinates: [111.08923 112.69194 106.94035 103.88033]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Step 10: Predicted Coordinates: [110.32642 111.70643 105.62438 102.30034]\n"
     ]
    }
   ],
   "source": [
    "def custom_sequential_predictions(model, scaler_coords, scaler_steering, X, start_index, n_predictions):\n",
    "    predictions = []\n",
    "    # Retrieve initial features and control inputs\n",
    "    current_features = X.iloc[start_index:start_index + 1][['x_closest', 'x_middle1', 'x_middle2', 'x_farthest', 'steering_angle']]\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        # Separate coordinates and steering for scaling\n",
    "        input_coords = current_features[['x_closest', 'x_middle1', 'x_middle2', 'x_farthest']]\n",
    "        input_steering = current_features[['steering_angle']]\n",
    "\n",
    "        # Scale the features for model input\n",
    "        scaled_coords = scaler_coords.transform(input_coords)\n",
    "        scaled_steering = scaler_steering.transform(input_steering)\n",
    "\n",
    "        # Combine scaled features for model input\n",
    "        model_input = np.hstack((scaled_coords, scaled_steering))\n",
    "\n",
    "        # Predict the next coordinates using the scaled features\n",
    "        predicted_coords = model.predict(model_input)[0]\n",
    "        predictions.append(predicted_coords)\n",
    "\n",
    "        # Update current_features for the next prediction\n",
    "        # Creating a new DataFrame for next prediction input\n",
    "        next_features = pd.DataFrame([predicted_coords], columns=['x_closest', 'x_middle1', 'x_middle2', 'x_farthest'])\n",
    "        next_features['steering_angle'] = X.iloc[start_index + i + 1]['steering_angle'] if start_index + i + 1 < len(X) else X.iloc[-1]['steering_angle']\n",
    "\n",
    "        # Replace current features with next_features\n",
    "        current_features = next_features\n",
    "\n",
    "        print(f\"Step {i + 1}: Predicted Coordinates: {predicted_coords}\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "custom_df = pd.DataFrame({\n",
    "    'x_closest': [120] * 10,  \n",
    "    'x_middle1': [120] * 10,\n",
    "    'x_middle2': [120] * 10,\n",
    "    'x_farthest': [120] * 10,\n",
    "    'steering_angle': [0] * 10 \n",
    "})\n",
    "\n",
    "start_index = 0\n",
    "n_predictions = 10\n",
    "custom_predictions = custom_sequential_predictions(model, scaler_coords, scaler_steering, custom_df, start_index, n_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea0dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model.save('NN_standscale.h5')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b23a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the scalers to disk\n",
    "with open('scaler_coords_standard.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_coords, file)\n",
    "\n",
    "with open('scaler_steering_standard.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_steering, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae37bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1995f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
